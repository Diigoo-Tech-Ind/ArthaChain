#!/usr/bin/env python3
"""Prophet Time Series Training Script"""
import os
import pandas as pd
from prophet import Prophet
import requests

JOB_ID = os.environ.get("ARTHA_JOB_ID", "unknown")
MODEL_PATH = "/model"
DATA_PATH = "/data"
PROOF_SERVICE_URL = os.environ.get("PROOF_SERVICE_URL", "http://localhost:8085")

def submit_train_proof(step: int, loss: float, digest: str):
    try:
        requests.post(f"{PROOF_SERVICE_URL}/proof/submit",
            json={"job_id": JOB_ID, "proof_type": "TrainStep", "step": step, "loss": loss}, timeout=10)
    except:
        pass

def main():
    print(f"ðŸš€ Prophet Training - Job: {JOB_ID}")
    
    # Load or generate data
    if os.path.exists(DATA_PATH):
        df = pd.read_csv(os.path.join(DATA_PATH, "train.csv"))
    else:
        # Generate dummy data
        import numpy as np
        dates = pd.date_range('2020-01-01', periods=365, freq='D')
        df = pd.DataFrame({'ds': dates, 'y': np.random.randn(365).cumsum() + 100})
    
    # Train model
    model = Prophet()
    model.fit(df)
    
    # Calculate loss (MAPE)
    future = model.make_future_dataframe(periods=30)
    forecast = model.predict(future)
    actual = df['y'].values[-30:] if len(df) > 30 else df['y'].values
    predicted = forecast['yhat'].values[-len(actual):]
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    
    submit_train_proof(0, mape, f"0x{hash(str(mape)):016x}")
    
    # Save model
    os.makedirs(MODEL_PATH, exist_ok=True)
    import pickle
    with open(os.path.join(MODEL_PATH, "model.pkl"), 'wb') as f:
        pickle.dump(model, f)
    
    print(f"âœ… Training complete! MAPE: {mape:.2f}%")

if __name__ == "__main__":
    import numpy as np
    main()

